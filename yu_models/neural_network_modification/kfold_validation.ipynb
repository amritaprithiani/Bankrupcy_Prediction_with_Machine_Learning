{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146924, 18)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(146924,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import and clean dataset\n",
    "\n",
    "df = pd.read_csv(Path(\"../../Resources/relabeled_data.csv\"))\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Set X and y\n",
    "\n",
    "X = df.drop(columns='status')\n",
    "y = df['status']\n",
    "\n",
    "# Scale X\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Resampling\n",
    "sampler = SMOTE(random_state=1)\n",
    "X_resample, y_resample = sampler.fit_resample(X_scaled, y)\n",
    "display(X_resample.shape)\n",
    "display(y_resample.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\fintech_material\\project2\\yu_models\\neural_network_modification\\kfold_validation.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/fintech_material/project2/yu_models/neural_network_modification/kfold_validation.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m svc_model \u001b[39m=\u001b[39m SVC(kernel\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrbf\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/fintech_material/project2/yu_models/neural_network_modification/kfold_validation.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m### Tensorflow Keras Sequential ###\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/fintech_material/project2/yu_models/neural_network_modification/kfold_validation.ipynb#X10sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m nn_model_1 \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mload_model(Path(\u001b[39m\"\u001b[39m\u001b[39m../../Resources/neural_network_models/four_layers.h5\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/fintech_material/project2/yu_models/neural_network_modification/kfold_validation.ipynb#X10sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# first hidden layer = 16\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/fintech_material/project2/yu_models/neural_network_modification/kfold_validation.ipynb#X10sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# second hidden layer = 8\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/fintech_material/project2/yu_models/neural_network_modification/kfold_validation.ipynb#X10sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# third hidden layer = 4\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/fintech_material/project2/yu_models/neural_network_modification/kfold_validation.ipynb#X10sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# optimizer = 'nadam'\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/fintech_material/project2/yu_models/neural_network_modification/kfold_validation.ipynb#X10sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# epochs = 100\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/fintech_material/project2/yu_models/neural_network_modification/kfold_validation.ipynb#X10sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m nn_model_2 \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mload_model(Path(\u001b[39m\"\u001b[39m\u001b[39m../../Resources/neural_network_models/96nodes_4layers_32epochs.h5\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "### SKLearn MLP Classifier ###\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp_model = MLPClassifier()\n",
    "# first hidden layer = 100\n",
    "# activation = 'relu'\n",
    "# optimizer = 'adam'\n",
    "# epochs = 200\n",
    "\n",
    "### SKLearn SVC: kernel = rbf ###\n",
    "from sklearn.svm import SVC\n",
    "svc_model = SVC(kernel='rbf')\n",
    "\n",
    "\n",
    "### Tensorflow Keras Sequential ###\n",
    "nn_model_1 = tf.keras.models.load_model(Path(\"../../Resources/neural_network_models/four_layers.h5\"))\n",
    "# first hidden layer = 16\n",
    "# second hidden layer = 8\n",
    "# third hidden layer = 4\n",
    "# fourth hidden layer = 2\n",
    "# hidden layer activation = 'selu'\n",
    "# output layer activation = 'softplus'\n",
    "# optimizer = 'nadam'\n",
    "# epochs = 100\n",
    "\n",
    "nn_model_2 = tf.keras.models.load_model(Path(\"../../Resources/neural_network_models/96nodes_4layers_32epochs.h5\"))\n",
    "# first hidden layer = 96\n",
    "# second hidden layer = 48\n",
    "# third hidden layer = 24\n",
    "# fourth hidden layer = 12\n",
    "# hidden layer activation = 'selu'\n",
    "# output layer activation = 'softplus'\n",
    "# optimizer = 'nadam'\n",
    "# epochs = 32\n",
    "\n",
    "### ImbLearn Easy Ensemble Classifier ###\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "eec_model = EasyEnsembleClassifier()\n",
    "\n",
    "### ImbLearn RUS Boost Classifier ###\n",
    "from imblearn.ensemble import RUSBoostClassifier\n",
    "rbc_model = RUSBoostClassifier()\n",
    "\n",
    "### ImbLearn Balanced Baggig Classifier ###\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "bbc_model = BalancedBaggingClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kFold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ordered dictionary that stores model instances\n",
    "from collections import OrderedDict\n",
    "\n",
    "# X_resample, y_resample\n",
    "sklearn_dictionary = OrderedDict()\n",
    "sklearn_dictionary['MLPClassifier'] = mlp_model\n",
    "sklearn_dictionary['SVC kernel rbf'] = svc_model\n",
    "\n",
    "# X_resample, y_resample\n",
    "nn_dictionary = OrderedDict()\n",
    "nn_dictionary['Neural Network 1'] = nn_model_1\n",
    "nn_dictionary['Neural Network 2'] = nn_model_2\n",
    "\n",
    "# X_scaled, y\n",
    "imblearn_dictionary = OrderedDict()\n",
    "imblearn_dictionary['Easy Ensemble Classifier'] = eec_model\n",
    "imblearn_dictionary['RUS Boost Classifier'] = rbc_model\n",
    "imblearn_dictionary['Balanced Bagging Classifier'] = bbc_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function to perform KFolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_prediction(model, X_train, X_test, y_train):\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    prediction_array = model.predict(X_test)\n",
    "    \n",
    "    return prediction_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_kfold_split(model, X, y):\n",
    "\n",
    "    kfold = KFold(n_splits=5)\n",
    "\n",
    "    for train_index, test_index in kfold.split(X):\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        prediction =  apply_prediction(model, X_train, X_test, y_train)\n",
    "        return y_test, prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_kfold_predictions(models_dict, X, y):\n",
    "\n",
    "    counter = 0\n",
    "    prediction_dict = {}\n",
    "\n",
    "    for key, value in models_dict.items():\n",
    "\n",
    "        kfold = KFold(n_splits=5)\n",
    "\n",
    "        for train_index, test_index in kfold.split(X):\n",
    "            \n",
    "            counter += 1\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            prediction =  apply_prediction(value, X_train, X_test, y_train)\n",
    "            \n",
    "            df = pd.concat([pd.Series(y_test), pd.Series(prediction)], axis=1)\n",
    "            df.columns = ['test', 'pred']\n",
    "\n",
    "            prediction_dict[f\"{key}_iter{counter}\"] = df\n",
    "\n",
    "        return prediction_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fast performing machine learning dict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "lr = LogisticRegression()\n",
    "rf_classifier = RandomForestClassifier(n_estimators = 5, criterion = 'entropy')\n",
    "\n",
    "fast_performing_ml_dict = OrderedDict()\n",
    "fast_performing_ml_dict['Logistic Regression'] = lr\n",
    "fast_performing_ml_dict['Random Forest Classifier'] = rf_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = combine_kfold_predictions(fast_performing_ml_dict, X_resample, y_resample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression_iter1':        test  pred\n",
       " 0         0     1\n",
       " 1         0     1\n",
       " 2         0     1\n",
       " 3         0     1\n",
       " 4         0     1\n",
       " ...     ...   ...\n",
       " 29380     0     1\n",
       " 29381     0     1\n",
       " 29382     0     1\n",
       " 29383     0     1\n",
       " 29384     0     1\n",
       " \n",
       " [29385 rows x 2 columns],\n",
       " 'Logistic Regression_iter2':        test  pred\n",
       " 29385   0.0   NaN\n",
       " 29386   0.0   NaN\n",
       " 29387   0.0   NaN\n",
       " 29388   0.0   NaN\n",
       " 29389   0.0   NaN\n",
       " ...     ...   ...\n",
       " 29380   NaN   1.0\n",
       " 29381   NaN   1.0\n",
       " 29382   NaN   1.0\n",
       " 29383   NaN   0.0\n",
       " 29384   NaN   0.0\n",
       " \n",
       " [58770 rows x 2 columns],\n",
       " 'Logistic Regression_iter3':        test  pred\n",
       " 58770   0.0   NaN\n",
       " 58771   0.0   NaN\n",
       " 58772   0.0   NaN\n",
       " 58773   0.0   NaN\n",
       " 58774   0.0   NaN\n",
       " ...     ...   ...\n",
       " 29380   NaN   1.0\n",
       " 29381   NaN   1.0\n",
       " 29382   NaN   0.0\n",
       " 29383   NaN   1.0\n",
       " 29384   NaN   1.0\n",
       " \n",
       " [58770 rows x 2 columns],\n",
       " 'Logistic Regression_iter4':        test  pred\n",
       " 88155   1.0   NaN\n",
       " 88156   1.0   NaN\n",
       " 88157   1.0   NaN\n",
       " 88158   1.0   NaN\n",
       " 88159   1.0   NaN\n",
       " ...     ...   ...\n",
       " 29380   NaN   0.0\n",
       " 29381   NaN   0.0\n",
       " 29382   NaN   0.0\n",
       " 29383   NaN   0.0\n",
       " 29384   NaN   0.0\n",
       " \n",
       " [58770 rows x 2 columns],\n",
       " 'Logistic Regression_iter5':         test  pred\n",
       " 117540   1.0   NaN\n",
       " 117541   1.0   NaN\n",
       " 117542   1.0   NaN\n",
       " 117543   1.0   NaN\n",
       " 117544   1.0   NaN\n",
       " ...      ...   ...\n",
       " 29379    NaN   0.0\n",
       " 29380    NaN   0.0\n",
       " 29381    NaN   0.0\n",
       " 29382    NaN   0.0\n",
       " 29383    NaN   0.0\n",
       " \n",
       " [58768 rows x 2 columns]}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ee04db7352e682cac186af61911f6acc7ec70cc0d9fa70de64442cbd59efbd7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
